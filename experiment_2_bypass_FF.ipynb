{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKZeVFG_3hgp",
        "outputId": "66c32dc5-28b0-4b6e-fbc6-888dd70b4ee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3, 12,  7,  2,  1,  9,  9, 12,  3,  9, 14,  1, 12, 13,  1],\n",
              "        [ 3,  1,  2,  9, 11,  8,  4,  5, 13,  6, 14,  1, 12,  2, 14],\n",
              "        [ 7, 14,  1,  4,  5,  0,  0,  9,  0, 10, 14,  3,  2,  4,  7],\n",
              "        [ 5, 12,  9,  6,  3,  0,  7,  7,  3,  3,  4,  5,  1,  1,  0],\n",
              "        [ 6,  8,  8, 13,  4,  3, 12,  2, 10,  8,  8,  5,  7,  9,  8],\n",
              "        [ 3, 13, 12,  7,  0,  4, 11,  7,  3, 11, 10,  6,  0,  6, 11],\n",
              "        [10, 10, 13,  4,  5, 12,  4, 10,  8, 13,  8, 11,  1,  3, 13],\n",
              "        [12,  5, 10,  5,  3,  3,  8, 12,  3,  1, 14,  2,  9, 10,  2],\n",
              "        [ 9,  7, 13,  1,  8, 13,  1,  5, 12, 10, 10, 11,  2, 13,  0],\n",
              "        [ 0,  1, 11,  2,  2, 11, 12,  1,  4, 10,  0, 11,  0,  6, 10],\n",
              "        [ 6,  5,  0, 12, 10, 14, 10, 10,  5, 13, 12, 10, 13, 14, 11],\n",
              "        [ 0,  4,  8,  5, 11, 12,  5, 12,  4,  7, 12,  9,  6,  2,  8],\n",
              "        [ 4, 11, 12, 12,  2,  2,  8,  8, 12,  3,  4,  2,  4, 11, 10],\n",
              "        [12,  2, 10,  7, 11,  2,  0,  2,  3,  0,  8,  3,  1,  1,  0],\n",
              "        [ 7,  2,  3,  7,  5, 10, 14,  0,  2,  8, 11,  5,  7,  0,  6]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import torch\n",
        "n_tokens = 16\n",
        "\n",
        "memory = torch.randint(0, n_tokens - 1, (n_tokens - 1, n_tokens - 1))\n",
        "\n",
        "memory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, dim_feedforward):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_head = n_head\n",
        "        self.dim_feedforward = dim_feedforward\n",
        "\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, n_head, batch_first=True)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, tgt, skip_feedforward=False, skip_self_attn=False):\n",
        "        mask = torch.triu(torch.ones(tgt.shape[1], tgt.shape[1]), diagonal=1).bool().cuda()\n",
        "        if not skip_self_attn:\n",
        "            tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=mask)[0]\n",
        "            tgt = tgt + tgt2\n",
        "        tgt = self.norm1(tgt)\n",
        "        if self.dim_feedforward > 0 and not skip_feedforward:\n",
        "            tgt2 = self.linear2(nn.functional.relu(self.linear1(tgt)))\n",
        "            tgt = tgt + tgt2\n",
        "        tgt = self.norm2(tgt)\n",
        "        return tgt\n",
        "\n",
        "class ToyTransformer(nn.Module):\n",
        "    def __init__(self, n_layers, d_model, n_head, hidden_size, n_tokens, max_len):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.d_model = d_model\n",
        "        self.n_head = n_head\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tokens = list(range(n_tokens))\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.embed = nn.Embedding(n_tokens, embedding_dim=d_model)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(d_model=d_model, n_head=n_head, dim_feedforward=hidden_size)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "        self.unembed = nn.Linear(d_model, n_tokens)\n",
        "\n",
        "    def forward(self, x, skip_feedforward=False, skip_self_attn=False, return_before_embedding=False):\n",
        "        tgt = self.embed(x)\n",
        "        for layer in self.layers:\n",
        "            tgt = tgt + layer(tgt, skip_feedforward=skip_feedforward, skip_self_attn=skip_self_attn)\n",
        "        if return_before_embedding:\n",
        "            return tgt\n",
        "        x = self.unembed(tgt)\n",
        "        return x\n",
        "\n",
        "    def train(self, lr=1e-3, batch_size=128, n_epochs=1000):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for _ in tqdm(range(n_epochs)):\n",
        "            batch = self.generate_data(batch_size)\n",
        "            optimizer.zero_grad()\n",
        "            output = self(batch)\n",
        "            loss = criterion(output[:, :-1].reshape(-1, len(self.tokens)), batch[:, 1:].reshape(-1))\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print('loss: ', loss.item())\n",
        "\n",
        "    def generate_data(self, batch_size):\n",
        "        bos = torch.tensor([self.tokens[0]] * batch_size).reshape(-1, 1)  # [batch_size, 1]\n",
        "        random_indices = torch.randint(0, n_tokens - 1, (batch_size, 2))  # [batch_size, 2]\n",
        "        next_tokens = memory[random_indices[:, 0], random_indices[:, 1]].unsqueeze(1)  # [batch_size, 1]\n",
        "        tensor = torch.cat([bos, random_indices, next_tokens], dim=1)\n",
        "        return tensor.cuda()\n",
        "\n"
      ],
      "metadata": {
        "id": "IS1bkNxh3tHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "for hidden_size in [0, 16, 32]:\n",
        "    print('hidden_size: ', hidden_size)\n",
        "    sleep(1)\n",
        "    model = ToyTransformer(n_layers=1, d_model=8, n_head=4, hidden_size=hidden_size, n_tokens=n_tokens, max_len=4).cuda()\n",
        "    model.train(lr=1e-3, n_epochs=30000, batch_size=128)\n",
        "    samples = 1000\n",
        "    data = model.generate_data(samples)\n",
        "    output = (model(data[:,:-1])[:,-1,:].argmax(dim=-1))\n",
        "    print('Accuracy: ', output.eq(data[:,-1]).sum().item() / samples)\n",
        "    output = (model(data[:,:-1], skip_feedforward=True)[:,-1,:].argmax(dim=-1))\n",
        "    print('Accuracy without feedforward: ', output.eq(data[:,-1]).sum().item() / samples)\n",
        "    output = (model(data[:,:-1], skip_feedforward=True, skip_self_attn=True)[:,-1,:].argmax(dim=-1))\n",
        "    print('Accuracy without both: ', output.eq(data[:,-1]).sum().item() / samples)\n",
        "    sleep(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIm97ajP31EE",
        "outputId": "f537bc1c-b962-4678-ebc3-6bae61c7a34c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_size:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30000/30000 [01:25<00:00, 351.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.1032800674438477\n",
            "Accuracy:  0.757\n",
            "Accuracy without feedforward:  0.757\n",
            "Accuracy without both:  0.134\n",
            "hidden_size:  16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30000/30000 [01:37<00:00, 306.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  1.9600681066513062\n",
            "Accuracy:  0.884\n",
            "Accuracy without feedforward:  0.116\n",
            "Accuracy without both:  0.114\n",
            "hidden_size:  32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30000/30000 [01:38<00:00, 304.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  1.8287297487258911\n",
            "Accuracy:  0.985\n",
            "Accuracy without feedforward:  0.136\n",
            "Accuracy without both:  0.089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelWrapper(nn.Module):\n",
        "    def __init__(self, model, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.hidden_layer = nn.Linear(model.d_model, hidden_dim)\n",
        "        self.output_layer = nn.Linear(hidden_dim, model.d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tgt = self.model(x, skip_feedforward=True, return_before_embedding=True)[:,-1,:]\n",
        "        x = self.hidden_layer(tgt)\n",
        "        x = torch.nn.functional.relu(x)\n",
        "        x = self.output_layer(x)\n",
        "        tgt = tgt + x\n",
        "        x = model.unembed(x)\n",
        "        return x\n",
        "\n",
        "wrapper = ModelWrapper(model, hidden_dim=2).cuda()\n",
        "optimizer = optim.Adam(wrapper.parameters(), lr=1e-2)\n",
        "model.requires_grad_(False)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for batch in tqdm(range(10000)):\n",
        "    optimizer.zero_grad()\n",
        "    data = model.generate_data(128)\n",
        "    output = wrapper(data[:,:-1])\n",
        "    loss = criterion(output, data[:,-1])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGWr5NrA4HAQ",
        "outputId": "736d05d1-d986-4617-a05a-2ad5b386bdfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:19<00:00, 501.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3522305488586426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = 1000\n",
        "data = model.generate_data(samples)\n",
        "output = wrapper(data[:,:-1]).argmax(dim=-1)\n",
        "print('Accuracy: ', output.eq(data[:,-1]).sum().item() / samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElTsru_G392E",
        "outputId": "18831e1b-c17b-4e8b-d80a-f0f8418426b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbI8Rs5DEcBI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
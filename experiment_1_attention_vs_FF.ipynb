{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Link to experiment 2]( )"
      ],
      "metadata": {
        "id": "rosNbjhFHIkP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goJLyzhCJ5mC",
        "outputId": "a12f3706-1405-432f-aca7-0758660b4ddf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  4, 10, 13, 11,  3,  9,  0, 17, 13,  6, 10,  3,  8,  4, 16,  9, 11,\n",
              "         17, 10],\n",
              "        [ 0,  7, 18, 18,  4,  1,  8, 13, 19,  6, 10, 12, 13,  2,  8, 10,  6, 18,\n",
              "          2,  6],\n",
              "        [ 4, 10, 10, 19, 17,  2, 16,  6, 17, 12, 16, 18,  4, 10,  1, 15,  5, 17,\n",
              "          7, 12],\n",
              "        [10,  3, 12,  6,  3, 18, 10,  9,  5,  6, 18, 10, 12, 16, 11,  6,  4, 15,\n",
              "          2,  7],\n",
              "        [16,  7,  2,  0,  7,  0,  9,  6, 12, 11, 18, 11, 19, 14, 11,  1, 15,  6,\n",
              "          8, 18],\n",
              "        [18,  9, 18,  4, 18, 10,  4, 12, 17,  8,  3, 12, 19,  3, 19, 17, 12, 13,\n",
              "         18, 14],\n",
              "        [ 6, 17, 19, 11,  9,  0, 17, 10,  8,  7, 19,  7,  2,  1, 12, 18, 15, 14,\n",
              "          3,  1],\n",
              "        [ 0, 10,  7, 13, 19, 16, 19, 19,  6, 13,  1,  7,  8, 16, 10, 15, 11, 14,\n",
              "         11, 11],\n",
              "        [ 2,  8, 15,  4, 19,  3,  9,  6, 14,  5,  1, 19, 15, 19,  6, 17,  2,  6,\n",
              "          6, 15],\n",
              "        [17, 10, 10, 18,  2,  9,  7,  5,  7,  9, 18,  2,  7, 17, 17, 18, 16, 14,\n",
              "         17,  6],\n",
              "        [ 4,  7, 16, 13,  8,  8,  8, 14, 16,  2,  9, 10,  3,  6,  1,  0, 12,  9,\n",
              "         15,  6],\n",
              "        [ 3, 17, 14, 16, 11,  0, 10,  5,  2, 17, 18,  3, 11, 14,  3,  8,  6, 14,\n",
              "          3,  1],\n",
              "        [14, 19, 19,  6,  4, 12,  5,  9, 19,  3, 17, 15, 19, 18, 11,  1,  5,  1,\n",
              "          3,  3],\n",
              "        [ 4,  8,  4,  4, 11,  9,  6, 11, 10, 12,  3, 15,  4, 12, 16, 19, 15, 18,\n",
              "         18,  2],\n",
              "        [11,  5, 18, 17, 19,  6,  7, 14, 12,  6, 13, 18, 14,  2, 19, 16,  0,  6,\n",
              "          0,  6],\n",
              "        [11, 10, 19, 14, 17,  9,  0,  5,  6,  1, 18,  9, 11,  6,  2, 14,  8, 17,\n",
              "         10, 10],\n",
              "        [ 1, 17, 18, 18, 11,  5, 15,  5,  3,  0, 18, 19,  2, 14, 11, 16,  3,  9,\n",
              "          5,  7],\n",
              "        [16,  4,  8, 16, 10,  1, 13, 13,  8,  7, 13,  8, 19, 17, 14, 10,  6,  2,\n",
              "          6, 17],\n",
              "        [ 1, 19, 18,  7, 17, 12,  2, 16, 15, 11,  0, 15,  0,  1, 17,  4,  9, 17,\n",
              "          5, 15],\n",
              "        [ 8, 16,  5, 18,  9,  5, 16, 12, 18, 13,  3,  0, 12,  5,  8, 11, 10,  5,\n",
              "          5, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "n_tokens = 21\n",
        "\n",
        "memory = torch.randint(0, n_tokens - 1, (n_tokens - 1, n_tokens - 1))\n",
        "\n",
        "memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVYYNP1tJ5mZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_head, dim_feedforward):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_head = n_head\n",
        "        self.dim_feedforward = dim_feedforward\n",
        "\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, n_head, batch_first=True)\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, tgt):\n",
        "        mask = torch.triu(torch.ones(tgt.shape[1], tgt.shape[1]), diagonal=1).bool().cuda()\n",
        "        tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=mask)[0]\n",
        "        tgt = tgt + tgt2\n",
        "        tgt = self.norm1(tgt)\n",
        "        if self.dim_feedforward > 0:\n",
        "            tgt2 = self.linear2(nn.functional.relu(self.linear1(tgt)))\n",
        "            tgt = tgt + tgt2\n",
        "        tgt = self.norm2(tgt)\n",
        "        return tgt\n",
        "\n",
        "class ToyTransformer(nn.Module):\n",
        "    def __init__(self, n_layers, d_model, n_head, hidden_size, n_tokens, max_len):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.d_model = d_model\n",
        "        self.n_head = n_head\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tokens = list(range(n_tokens))\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.embed = nn.Embedding(n_tokens, embedding_dim=d_model)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(d_model=d_model, n_head=n_head, dim_feedforward=hidden_size)\n",
        "            for _ in range(n_layers)\n",
        "        ])\n",
        "        self.unembed = nn.Linear(d_model, n_tokens)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tgt = self.embed(x)\n",
        "        for layer in self.layers:\n",
        "            tgt = tgt + layer(tgt)\n",
        "        x = self.unembed(tgt)\n",
        "        return x\n",
        "\n",
        "    def train(self, lr=1e-3, batch_size=128, n_epochs=1000):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for _ in tqdm(range(n_epochs)):\n",
        "            batch = self.generate_data(batch_size)\n",
        "            optimizer.zero_grad()\n",
        "            output = self(batch)\n",
        "            loss = criterion(output[:, :-1].reshape(-1, len(self.tokens)), batch[:, 1:].reshape(-1))\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print('loss: ', loss.item())\n",
        "\n",
        "    def generate_data(self, batch_size):\n",
        "        bos = torch.tensor([self.tokens[0]] * batch_size).reshape(-1, 1)  # [batch_size, 1]\n",
        "        random_indices = torch.randint(0, n_tokens - 1, (batch_size, 2))  # [batch_size, 2]\n",
        "        next_tokens = memory[random_indices[:, 0], random_indices[:, 1]].unsqueeze(1)  # [batch_size, 1]\n",
        "        tensor = torch.cat([bos, random_indices, next_tokens], dim=1)\n",
        "        return tensor.cuda()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI7K9f7YJ5me",
        "outputId": "57f94a54-a34a-4568-f269-055ae2b3e057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_size:  0 nheads:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
            "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n",
            "100%|██████████| 50000/50000 [02:25<00:00, 343.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.5544683933258057\n",
            "0.45614\n",
            "hidden_size:  0 nheads:  4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [02:24<00:00, 346.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.4965195655822754\n",
            "0.53126\n",
            "hidden_size:  0 nheads:  8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [02:21<00:00, 352.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.4809160232543945\n",
            "0.5849\n",
            "hidden_size:  16 nheads:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [02:43<00:00, 305.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.399559259414673\n",
            "0.68864\n",
            "hidden_size:  16 nheads:  4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [02:45<00:00, 302.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.2880663871765137\n",
            "0.77488\n",
            "hidden_size:  16 nheads:  8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [02:44<00:00, 304.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.227630853652954\n",
            "0.80994\n",
            "hidden_size:  32 nheads:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [02:44<00:00, 303.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.1739981174468994\n",
            "0.89682\n",
            "hidden_size:  32 nheads:  4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [02:42<00:00, 308.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.169658899307251\n",
            "0.87494\n",
            "hidden_size:  32 nheads:  8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [02:44<00:00, 303.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  2.1942458152770996\n",
            "0.8586\n"
          ]
        }
      ],
      "source": [
        "from time import sleep\n",
        "for hidden_size in [0, 16, 32]:\n",
        "    for nheads in [2, 4, 8]:\n",
        "        print('hidden_size: ', hidden_size, 'nheads: ', nheads)\n",
        "        sleep(1)\n",
        "        model = ToyTransformer(n_layers=1, d_model=8, n_head=nheads, hidden_size=hidden_size, n_tokens=n_tokens, max_len=4).cuda()\n",
        "        model.train(lr=1e-3, n_epochs=50000, batch_size=512)\n",
        "        samples = 50000\n",
        "        data = model.generate_data(samples)\n",
        "        # print(data)\n",
        "        output = (model(data[:,:-1])[:,-1,:].argmax(dim=-1))\n",
        "        # print(output)\n",
        "        print(output.eq(data[:,-1]).sum().item() / samples)\n",
        "        sleep(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m87vLGLKeJjB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}